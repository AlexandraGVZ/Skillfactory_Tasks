Project – Two Sigma Connect: Rental Listing Inquiries  
=============================  
 
Автор: Александра Гвоздева  
--------------------------  

**Задание**  

Предсказание степени заинтересованности объектом недвижимости в зависимости от его характеристик. 


Описание признаков    
------------------       

* bathrooms: количество ванных комнат
* bedrooms: количество спален
* building_id: идентификатор здания
* created: дата создания записи
* description: описание объекта недвижимости
* display_address: отображаемый адрес
* features: ключевые черты объекта недвижимости (например, лифт)
* latitude: широта
* listing_id: идентификатор записи
* longitude: долгота
* manager_id: идентификатор менеджера
* photos: фотографии (ссылки)
* price: цена в долларах США
* street_address: адрес
* interest_level: уровень заинтересованности, целевая переменная ("высокий", "средний", "низкий")


Выводы:  
-------  

1. Для решения данной задачи были испробованы 4 модели: логистическая регрессия, случайный лес, ада-бустинг и градиентный бустинг. Было показано, что случайный лес плохо подходит для решения данной задачи, т.к. происходит переобучение. При борьбе с переобучением целевая метрика снижается и становится хуже, чем у всех остальных моделей.
2. Обработка данных значительно улучшает целевую метрику. Наилучшие результаты на обработанных данных были получены для  градиентного бустинга (f1_score_macro=0.51 на кросс-валидации).
3. Обработка данных включает в себя удаление ошибок в данных и feature engineering. В ходе feature engineering были получены 39 дополнительных признаков (включая dummy-признаки и полиномиальные признаки).
4. Применение метода главных компонент к сильно скоррелированным признакам по-разному влияет на модели. Логистическая регрессия и ада-бустинг реагируют ухудшением метрики. Для градиентного бустинга и случайного леса наблюдается незначительное повышение метрики. Логистическая регрессия также плохо реагирует на простое удаление одного из сильно скоррелированных признаков.
5. Добавление полиномиальных признаков по-разному сказывается на разных моделях. Для логистической регрессиии метрика увеличивается. Для ада-бустинга метрика тоже увеличивается, но не так значительно. Для градиентного бустинга метрика ухудшается. Для случайного леса метрика увеличивается.
6. После проведения всех расчетов градиентный бустинг дает самое высокое значение метрики f1_score_macro на кросс-валидации, но при этом сильно переобучается. С переобучением удается справиться путем ограничения глубины дерева, уменьшения learning_rate и задания subsample=0.5. Итоговая метрика (при не переобученном градиентном бустинге) равна 0.51.