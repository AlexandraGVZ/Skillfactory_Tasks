Project - Bank credit scoring  
=============================  
 
Автор: Александра Гвоздева  
--------------------------  

**Задание**  

Построение модели для прогнозирования вероятности дефолта заемщика.  

Описание признаков    
------------------       

* client_id - идентификатор клиента   
* education - уровень образования  
* sex - пол заемщика  
* age - возраст заемщика  
* car - флаг наличия автомобиля  
* car_type - флаг автомобиля иномарки  
* decline_app_cnt - количество отказанных прошлых заявок  
* good_work - флаг наличия “хорошей” работы  
* bki_request_cnt - количество запросов в БКИ  
* home_address - категоризатор домашнего адреса  
* work_address - категоризатор рабочего адреса  
* income - доход заемщика  
* foreign_passport - наличие загранпаспорта  
* sna - связь заемщика с клиентами банка  
* first_time - давность наличия информации о заемщике  
* score_bki - скоринговый балл по данным из БКИ  
* region_rating - рейтинг региона  
* app_date - дата подачи заявки  
* default - флаг дефолта по кредиту  

В результате работы над данными:  
--------------------------------  

* был произведен разведывательный анализ данных  
* была произведена очистка данных и обработка выбросов (в финальной версии удаления и сглаживания выбросов нет, так как это ухудшало качество модели, оставлено только логарифмирование и использование RobustScaler для непрерывных признаков)  
* созданы новые признаки  
* отобраны признаки для модели по значимости  
* подобраны оптимальные гиперпараметры для модели  
* проведена проверка модели на переобучение - результат отрицательный  
* было принято участие в соревновании на kaggle.com [ссылка](https://www.kaggle.com/c/sf-scoring "Перейти к соревнованию")  

Были достигнуты следующие показатели:  
-------------------------------------  

* ROC AUC - 0.74
* F1-score - 0.34
* Precision score - 0.67
* Recall score - 0.23

Выводы:  
-------
* Разведывательный анализ данных показал, что данные достаточно чистые. Пропусков немного (только в колонке education). Пропуски в колонке education были заполнены случайными значениями из уже существующих.
* Колонки в датасете делятся на бинарные, категориальные и с непрерывным типом данных. Бинарные колонки были обработаны с помощью LabelEncoder, категориальные - с помощью OneHotEncoder.
* Некоторые колонки с непрерывным типом данных ('decline_app_cnt', 'bki_request_cnt', 'income') имеют "тяжелый" правый хвост. Это колонки были прологарифмированы. Операция была проведена над объединенным датасетом (трейн + тест).
* Были сгенерированы дополнительные непрерывные признаки (4 колонки) и категориальные признаки (3 колонки). Новые категориальные признаки повышают качество модели. Новые непрерывные признаки сильно скоррелированы, поэтому их использование ухудшает качество модели. Три наиболее скоррелированных признака были обработаны методом главных компонент. Это дало улучшение целевой метрики.
* Работа с выбросами в данном датасете не принесла улучшения качества модели. Выбросы были классифицированы методом IQR (фактически это не выбросы, а просто отличающиеся значения в датасете). Т.к. удаление "выбросов" приводит к ухудшению качества модели, "выбросы" было решено оставить.
* Была предпринята попытка сгенерировать полиномиальные признаки (вручную и с помощью функции Polynomial Features). Некоторые полиномиальные признаки помогают улучшить целевую метрику, а некоторые, наоборот, ухудшают. Были оставлены только признаки, помогающие улучшить модель.
* Наибольшее значение для модели имеют признаки score_bki и sna.
* Было испробовано добавление параметра WоE для наиболее значимых признаков score_bki и sna (сначала в качестве дополнительного признака, а потом с заменой исходных признаков). Это не принесло улучшения качества модели.
* Удаление наименее значимого непрерывного признака age улучшает целевую метрику.
* Было испробовано деление выборки на обучающую и тестовую с помощью StratifiedShuffleSplit (деление на части с учетом долей классов). Это не дало увеличения целевой метрики. От данного способа деления выборки было принято решение отказаться в пользу train_test_split.
* С помощью метода GridSerchCV были подобраны оптимальные параметры для модели логистической регрессии. От значений по умолчанию отличается только параметр class_weight ('balanced').
* Был подобран гиперпараметр С=0.01, что соответствует максимальному вкладу регуляризации. Это дало улучшение целевой метрики по сравнению с С=1.0 (значение по умолчанию).
* Использование логистической регрессии с оптимизированными параметрами позволяет получить значение метрики f1_score, равное 0.34. Переобучения модели нет.



  


 

 




